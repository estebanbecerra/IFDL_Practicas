import torch
import torchvision.models as models
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, TensorDataset
import torch.nn as nn
import deepspeed
import time

# Parámetros básicos del experimento
batch_size = 128
num_epochs = 1
num_classes = 10

# Transformaciones estándar
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# Generar dataset sintético
input_images = torch.rand((batch_size, 3, 224, 224))
labels = torch.randint(0, num_classes, (batch_size,))

dataset = TensorDataset(input_images, labels)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)

# Modelo y criterio de pérdida
model = models.squeezenet1_1(weights='SqueezeNet1_1_Weights.IMAGENET1K_V1')
criterion = nn.CrossEntropyLoss()

# Inicializar DeepSpeed
model, optimizer, _, _ = deepspeed.initialize(
    model=model,
    model_parameters=model.parameters(),
    config='deepspeed_config.json'
)

model.train()

# Medir tiempo
start_time = time.time()

# Loop de entrenamiento con DeepSpeed
for epoch in range(num_epochs):
    running_loss = 0.0
    for inputs, targets in dataloader:
        inputs, targets = inputs.to(model.device), targets.to(model.device)

        outputs = model(inputs)
        loss = criterion(outputs, targets)

        model.backward(loss)
        model.step()

        running_loss += loss.item()

    print(f"Epoch {epoch+1}, Loss: {running_loss / len(dataloader):.4f}")

torch.cuda.empty_cache()

train_time = time.time() - start_time

# Guardar resultados
output_file = "../../outputs/train/squeezenet_train_gpu_deepspeed_results.txt"
with open(output_file, "w") as f:
    f.write(f"Training Time: {train_time:.2f} seconds\n")

print(f"Entrenamiento completado con DeepSpeed. Resultados guardados en {output_file}")
