Collecting deepspeed
  Using cached deepspeed-0.16.5-py3-none-any.whl
Collecting einops (from deepspeed)
  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)
Collecting hjson (from deepspeed)
  Using cached hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)
Collecting msgpack (from deepspeed)
  Using cached msgpack-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)
Collecting ninja (from deepspeed)
  Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)
Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from deepspeed) (2.2.4)
Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from deepspeed) (24.2)
Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from deepspeed) (7.0.0)
Collecting py-cpuinfo (from deepspeed)
  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)
Requirement already satisfied: pydantic>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from deepspeed) (2.10.3)
Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (from deepspeed) (2.6.0)
Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from deepspeed) (4.67.1)
Collecting nvidia-ml-py (from deepspeed)
  Using cached nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)
Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic>=2.0.0->deepspeed) (0.6.0)
Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.12/site-packages (from pydantic>=2.0.0->deepspeed) (2.27.1)
Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.12/site-packages (from pydantic>=2.0.0->deepspeed) (4.12.2)
Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (3.18.0)
Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (3.4.2)
Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (3.1.6)
Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (2025.3.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (12.4.127)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (12.4.127)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (12.4.127)
Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (9.1.0.70)
Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (12.4.5.8)
Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (11.2.1.3)
Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (10.3.5.147)
Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (11.6.1.9)
Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (12.3.1.170)
Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (0.6.2)
Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (2.21.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (12.4.127)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (12.4.127)
Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (3.2.0)
Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (75.8.0)
Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch->deepspeed) (1.13.1)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch->deepspeed) (1.3.0)
Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch->deepspeed) (3.0.2)
Using cached einops-0.8.1-py3-none-any.whl (64 kB)
Using cached hjson-3.1.0-py3-none-any.whl (54 kB)
Using cached msgpack-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)
Using cached ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)
Using cached nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)
Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)
Installing collected packages: py-cpuinfo, nvidia-ml-py, hjson, ninja, msgpack, einops, deepspeed
Successfully installed deepspeed-0.16.5 einops-0.8.1 hjson-3.1.0 msgpack-1.1.0 ninja-1.11.1.4 nvidia-ml-py-12.570.86 py-cpuinfo-9.0.0
[2025-03-30 18:10:37,032] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-30 18:10:38,133] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected VISIBLE_DEVICES=0: setting --include=localhost:0
[2025-03-30 18:10:38,133] [INFO] [runner.py:605:main] cmd = /opt/conda/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None scripts/train/entrenamiento_squeezenet_deepspeed.py --deepspeed --deepspeed_config config/deepspeed_config.json
[2025-03-30 18:10:43,408] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-03-30 18:10:43,944] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE=libnccl-dev=2.17.1-1+cuda12.1
[2025-03-30 18:10:43,944] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE_VERSION=2.17.1-1
[2025-03-30 18:10:43,944] [INFO] [launch.py:139:main] 0 NCCL_VERSION=2.17.1-1
[2025-03-30 18:10:43,944] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_DEV_PACKAGE_NAME=libnccl-dev
[2025-03-30 18:10:43,944] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE=libnccl2=2.17.1-1+cuda12.1
[2025-03-30 18:10:43,944] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE_NAME=libnccl2
[2025-03-30 18:10:43,944] [INFO] [launch.py:139:main] 0 NV_LIBNCCL_PACKAGE_VERSION=2.17.1-1
[2025-03-30 18:10:43,944] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0]}
[2025-03-30 18:10:43,944] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=1, node_rank=0
[2025-03-30 18:10:43,945] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})
[2025-03-30 18:10:43,945] [INFO] [launch.py:164:main] dist_world_size=1
[2025-03-30 18:10:43,945] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0
[2025-03-30 18:10:43,948] [INFO] [launch.py:256:main] process 2563 spawned with command: ['/opt/conda/bin/python', '-u', 'scripts/train/entrenamiento_squeezenet_deepspeed.py', '--local_rank=0', '--deepspeed', '--deepspeed_config', 'config/deepspeed_config.json']
My guessed rank = 0
[2025-03-30 18:10:49,224] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/opt/conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-03-30 18:10:49,955] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.16.5, git-hash=unknown, git-branch=unknown
[2025-03-30 18:10:49,955] [INFO] [comm.py:658:init_distributed] cdb=None
[2025-03-30 18:10:49,955] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-03-30 18:10:49,981] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 1
[2025-03-30 18:10:50,743] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
Using /home/estebanbecerraf/.cache/torch_extensions/py312_cu124 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/estebanbecerraf/.cache/torch_extensions/py312_cu124/fused_adam/build.ninja...
/opt/conda/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output multi_tensor_adam.cuda.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.12/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/lib/python3.12/site-packages/deepspeed/ops/csrc/adam -isystem /opt/conda/lib/python3.12/site-packages/torch/include -isystem /opt/conda/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.12/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.12/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_75,code=compute_75 -std=c++17 -c /opt/conda/lib/python3.12/site-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o 
[2/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.12/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/lib/python3.12/site-packages/deepspeed/ops/csrc/adam -isystem /opt/conda/lib/python3.12/site-packages/torch/include -isystem /opt/conda/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.12/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.12/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -c /opt/conda/lib/python3.12/site-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o 
[3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/opt/conda/lib/python3.12/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_adam.so
Loading extension module fused_adam...
Time to load fused_adam op: 70.12690591812134 seconds
[2025-03-30 18:12:00,983] [INFO] [logging.py:107:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adam as basic optimizer
[2025-03-30 18:12:00,989] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-03-30 18:12:00,991] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2025-03-30 18:12:00,991] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2025-03-30 18:12:00,991] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[2025-03-30 18:12:00,991] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000
[2025-03-30 18:12:00,991] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 500000000
[2025-03-30 18:12:00,991] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-03-30 18:12:00,991] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2025-03-30 18:12:01,460] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-03-30 18:12:01,463] [INFO] [utils.py:782:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB 
[2025-03-30 18:12:01,464] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 2.8 GB, percent = 39.2%
[2025-03-30 18:12:01,658] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-03-30 18:12:01,659] [INFO] [utils.py:782:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB 
[2025-03-30 18:12:01,659] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 2.8 GB, percent = 39.2%
[2025-03-30 18:12:01,659] [INFO] [stage_1_and_2.py:556:__init__] optimizer state initialized
[2025-03-30 18:12:01,808] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-03-30 18:12:01,809] [INFO] [utils.py:782:see_memory_usage] MA 0.01 GB         Max_MA 0.01 GB         CA 0.02 GB         Max_CA 0 GB 
[2025-03-30 18:12:01,809] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 2.8 GB, percent = 39.2%
[2025-03-30 18:12:01,813] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-03-30 18:12:01,814] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2025-03-30 18:12:01,814] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-03-30 18:12:01,814] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]
[2025-03-30 18:12:01,814] [INFO] [config.py:1000:print] DeepSpeedEngine configuration:
[2025-03-30 18:12:01,814] [INFO] [config.py:1004:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-03-30 18:12:01,814] [INFO] [config.py:1004:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-03-30 18:12:01,814] [INFO] [config.py:1004:print]   amp_enabled .................. False
[2025-03-30 18:12:01,814] [INFO] [config.py:1004:print]   amp_params ................... False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   bfloat16_enabled ............. False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   bfloat16_immediate_grad_update  False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   checkpoint_parallel_write_pipeline  False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   checkpoint_tag_validation_enabled  True
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   checkpoint_tag_validation_fail  False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x2b88a7adf740>
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   communication_data_type ...... None
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   curriculum_enabled_legacy .... False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   curriculum_params_legacy ..... False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   data_efficiency_enabled ...... False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   dataloader_drop_last ......... False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   disable_allgather ............ False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   dump_state ................... False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   dynamic_loss_scale_args ...... None
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   eigenvalue_enabled ........... False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   eigenvalue_gas_boundary_resolution  1
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   eigenvalue_layer_num ......... 0
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   eigenvalue_max_iter .......... 100
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   eigenvalue_stability ......... 1e-06
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   eigenvalue_tol ............... 0.01
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   eigenvalue_verbose ........... False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   elasticity_enabled ........... False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   fp16_auto_cast ............... False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   fp16_enabled ................. True
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   fp16_master_weights_and_gradients  False
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   global_rank .................. 0
[2025-03-30 18:12:01,820] [INFO] [config.py:1004:print]   grad_accum_dtype ............. None
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   gradient_accumulation_steps .. 1
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   gradient_clipping ............ 0.0
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   gradient_predivide_factor .... 1.0
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   graph_harvesting ............. False
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   initial_dynamic_scale ........ 65536
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   load_universal_checkpoint .... False
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   loss_scale ................... 0
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   memory_breakdown ............. False
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   mics_hierarchial_params_gather  False
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   mics_shard_size .............. -1
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   optimizer_legacy_fusion ...... False
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   optimizer_name ............... adam
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   optimizer_params ............. {'lr': 0.001}
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   pld_enabled .................. False
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   pld_params ................... False
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   prescale_gradients ........... False
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   scheduler_name ............... None
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   scheduler_params ............. None
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   seq_parallel_communication_data_type  torch.float32
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   sparse_attention ............. None
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   sparse_gradients_enabled ..... False
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   steps_per_print .............. None
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   timers_config ................ enabled=True synchronized=True
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   train_batch_size ............. 128
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   train_micro_batch_size_per_gpu  128
[2025-03-30 18:12:01,821] [INFO] [config.py:1004:print]   use_data_before_expert_parallel_  False
[2025-03-30 18:12:01,822] [INFO] [config.py:1004:print]   use_node_local_storage ....... False
[2025-03-30 18:12:01,822] [INFO] [config.py:1004:print]   wall_clock_breakdown ......... False
[2025-03-30 18:12:01,822] [INFO] [config.py:1004:print]   weight_quantization_config ... None
[2025-03-30 18:12:01,822] [INFO] [config.py:1004:print]   world_size ................... 1
[2025-03-30 18:12:01,822] [INFO] [config.py:1004:print]   zero_allow_untested_optimizer  False
[2025-03-30 18:12:01,822] [INFO] [config.py:1004:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-03-30 18:12:01,822] [INFO] [config.py:1004:print]   zero_enabled ................. True
[2025-03-30 18:12:01,822] [INFO] [config.py:1004:print]   zero_force_ds_cpu_optimizer .. True
[2025-03-30 18:12:01,822] [INFO] [config.py:1004:print]   zero_optimization_stage ...... 2
[2025-03-30 18:12:01,822] [INFO] [config.py:990:print_user_config]   json = {
    "train_batch_size": 128, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.001
        }
    }, 
    "fp16": {
        "enabled": true
    }, 
    "zero_optimization": {
        "stage": 2
    }
}
/opt/conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
[2025-03-30 18:12:04,450] [INFO] [loss_scaler.py:183:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648
Epoch 1, Loss: 7.2305
[rank0]:[W330 18:12:04.831677363 collection.cpp:992] Warning: Failed to recover relationship between all profiler and kineto events: 1321 vs. 0  reassociated. (function reassociate)
Entrenamiento completado con DeepSpeed. Resultados guardados en outputs/train/squeezenet_train_gpu_deepspeed_results.txt
[rank0]:[W330 18:12:05.496931492 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[2025-03-30 18:12:07,960] [INFO] [launch.py:351:main] Process 2563 exits successfully.
